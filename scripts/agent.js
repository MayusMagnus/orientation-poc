// scripts/agent.js
//
// Agent cÃ´tÃ© front : appels OpenAI et logique de dÃ©cision.
// - conserve ton prompt "exigeant & bienveillant" pour decideNext (avec exceptions bourse)
// - ajoute Agent.recap() pour gÃ©nÃ©rer le rÃ©cap narratif (4 sections)

(function () {
  const Agent = {};
  let CONFIG = { apiKey: null, baseUrl: "https://api.openai.com/v1", model: "gpt-4o-mini" };

  Agent.configure = ({ apiKey, baseUrl, model }) => {
    if (apiKey) CONFIG.apiKey = apiKey;
    if (baseUrl) CONFIG.baseUrl = baseUrl;
    if (model) CONFIG.model = model;
  };

  function headers() {
    if (!CONFIG.apiKey) throw new Error("Code dâ€™accÃ¨s manquant.");
    return { "Content-Type": "application/json", Authorization: `Bearer ${CONFIG.apiKey}` };
  }

  async function chat(messages, { json = false, temperature = 0.3, max_tokens = 700 } = {}) {
    const body = { model: CONFIG.model, messages, temperature, max_tokens };
    if (json) body.response_format = { type: "json_object" };
    const res = await fetch(`${CONFIG.baseUrl.replace(/\/+$/,'')}/chat/completions`, {
      method: "POST", headers: headers(), body: JSON.stringify(body),
    });
    const data = await res.json();
    if (!res.ok) throw new Error(data?.error?.message || res.statusText || "Erreur OpenAI");
    return (data.choices?.[0]?.message?.content || "").trim();
  }

  function compactHistory(history, maxTurns = 30) {
    if (!Array.isArray(history)) return "";
    const last = history.slice(-maxTurns);
    return last.map(t => `${t.role === "user" ? "Ã‰lÃ¨ve" : "Agent"}: ${t.content}`).join("\n");
  }

  const J = (x) => JSON.stringify(x);
  const safeParseJSON = (s) => { try { return JSON.parse(s); } catch { return null; } };

  // === Decision: ask follow-up vs next question
  Agent.decideNext = async ({
    history = [], question, answer,
    hint_followup = "", followup_count = 0,
    previous_followups = [], last_answers = [],
    last_assistant = "",
    max_followups = 5,
    skip_revisit = false
  }) => {
    const sys = [
      "Tu es un conseiller dâ€™orientation exigeant et bienveillant. Tu t'adresses Ã  un(e) lycÃ©en(ne) franÃ§ais(e).",
      "RÃˆGLES:",
      "â€¢ Creuse chaque question jusquâ€™Ã  obtenir des Ã©lÃ©ments concrets (exemples, critÃ¨res mesurables, qui/quoi/oÃ¹/quand/combien/comment) sauf sur la question de la bourse.",
      "â€¢ RÃ©ponses vagues ou Â« je ne sais pas Â» â†’ pas satisfaisant: propose options, Ã©chelles (1-5), exemples.",
      "â€¢ NE JAMAIS rÃ©pÃ©ter une sous-question dÃ©jÃ  posÃ©e, ni reformuler exactement la question initiale, ni le DERNIER message de lâ€™agent.",
      "â€¢ Pour Ã©viter les rÃ©pÃ©titions, vÃ©rifie previous_followups et last_assistant et change dâ€™angle.",
      "â€¢ Max 5 follow-ups par question. Ensuite, passer et marquer pour reprise.",
      "â€¢ Respecte strictement la limite max de sous-questions transmise.",
      "â€¢ Si 'skip_revisit' est vrai, privilÃ©gie le passage Ã  la question suivante dÃ¨s qu'une rÃ©ponse minimale est donnÃ©e; ne cherche pas Ã  marquer pour reprise.",
      "RÃ©ponds UNIQUEMENT en JSON valide."
    ].join("\n");

    const user = {
      question,
      student_answer: answer,
      hint_followup,
      followup_count,
      max_followups,
      skip_revisit,
      previous_followups,
      last_assistant,
      last_answers,
      history_excerpt: compactHistory(history, 30),
      wanted_output: {
        answered: "boolean",
        next_action: "ask_followup | next_question",
        followup_question: "string (si ask_followup, formulation NOUVELLE, courte et concrÃ¨te, diffÃ©rente de previous_followups et de last_assistant)",
        missing_points: "string[]",
        reason: "string"
      }
    };

    const out = await chat(
      [{ role: "system", content: sys }, { role: "user", content: J(user) }],
      { json: true, temperature: 0.2, max_tokens: 550 }
    );

    const parsed = safeParseJSON(out) || {};
    if (typeof parsed.answered !== "boolean") parsed.answered = false;
    if (!parsed.next_action) parsed.next_action = parsed.answered ? "next_question" : "ask_followup";
    if (!Array.isArray(parsed.missing_points)) parsed.missing_points = [];
    if (parsed.next_action === "ask_followup" && !parsed.followup_question) {
      parsed.followup_question = "PrÃ©cise avec un exemple concret (oÃ¹, quand, durÃ©e, acteurs, budget).";
    }
    if (!parsed.reason) parsed.reason = parsed.answered ? "Couverture suffisante." : "Besoin de prÃ©cisions ciblÃ©es.";
    return parsed;
  };

  // === Reformulate a revisit question
  Agent.reformulate = async ({ original_question, last_answers = [], missing_points = [] }) => {
    const sys = "Reformule une question dâ€™orientation de maniÃ¨re ultra-ciblÃ©e et concrÃ¨te en franÃ§ais, sans intro.";
    const user = {
      original_question, last_answers, missing_points,
      instruction: "Produit UNE seule question courte, prÃ©cise, actionnable. RÃ©ponds en JSON {\"reformulated_question\":\"...\"}."
    };
    const out = await chat(
      [{ role: "system", content: sys }, { role: "user", content: J(user) }],
      { json: true, temperature: 0.3, max_tokens: 200 }
    );
    const parsed = safeParseJSON(out) || {};
    return { reformulated_question: parsed.reformulated_question || original_question };
  };

  // === Rephrase a follow-up to avoid duplication
  Agent.rephraseFollowup = async ({ base_followup, previous_followups = [], question, last_answers = [], last_assistant = "" }) => {
    const sys = "Tu proposes une variante de sous-question, courte, concrÃ¨te, diffÃ©rente des formulations prÃ©cÃ©dentes et du dernier message de lâ€™agent. Pas dâ€™intro.";
    const user = {
      base_followup, previous_followups, last_assistant, question, last_answers,
      constraints: [
        "Doit Ãªtre significativement diffÃ©rente des previous_followups ET de last_assistant",
        "Changer dâ€™angle: quand/oÃ¹/combien/qui/comment mesurer/exemple chiffrÃ©"
      ],
      wanted_output: { question: "string" }
    };
    const out = await chat(
      [{ role: "system", content: sys }, { role: "user", content: J(user) + '\nRÃ©ponds en JSON {"question":"..."}' }],
      { json: true, temperature: 0.4, max_tokens: 150 }
    );
    const parsed = safeParseJSON(out) || {};
    return { question: parsed.question || base_followup };
  };

  // === Summarize (dÃ©jÃ  utilisÃ© par l'app) â€” laissÃ© en place
  Agent.summarize = async ({ history = [] }) => {
    const sys = [
      "Tu analyses le dialogue pour produire une synthÃ¨se structurÃ©e et concise.",
      "RÃ©ponds UNIQUEMENT en JSON avec les clÃ©s:",
      "objectifs:string[], priorites:string[], format_ideal:string, langue:string, niveau_actuel:string, niveau_cible:string, ambition_progression:string, projet_phrase_ultra_positive:string, meta:object"
    ].join("\n");

    const user = { history_excerpt: compactHistory(history, 50) };
    const out = await chat(
      [{ role: "system", content: sys }, { role: "user", content: J(user) }],
      { json: true, temperature: 0.3, max_tokens: 700 }
    );
    const parsed = safeParseJSON(out) || {};
    // normalisation minimale
    parsed.objectifs = Array.isArray(parsed.objectifs) ? parsed.objectifs : [];
    parsed.priorites = Array.isArray(parsed.priorites) ? parsed.priorites : [];
    parsed.meta = typeof parsed.meta === "object" && parsed.meta !== null ? parsed.meta : {};
    return parsed;
  };

  // === Recap (nouveau) â€” 4 paragraphes narratifs
  Agent.recap = async ({ history = [], summary = {} }) => {
    // Paragraphes dÃ©faut (si lâ€™API Ã©choue ou JSON invalide)
    const defaults = {
      self_learning:
        "Si tu te reconnais dans ces questions, câ€™est que tu es curieux(se), que tu aimes explorer de nouvelles expÃ©riences et apprendre en participant activement. Tu auras sans doute besoin dâ€™un environnement oÃ¹ lâ€™on valorise lâ€™Ã©change, la discussion et lâ€™initiative. Si ce nâ€™est pas vraiment ton cas, tu pourrais prÃ©fÃ©rer des contextes plus structurÃ©s, avec des repÃ¨res clairs et un cadre rassurant. Cela ne tâ€™empÃªche pas de rÃ©ussir Ã  lâ€™Ã©tranger, mais il sera important que tu puisses avancer Ã  ton rythme et trouver du soutien autour de toi.",
      academic:
        "Si tu attaches beaucoup dâ€™importance Ã  ces questions, câ€™est que la rÃ©ussite acadÃ©mique et la rÃ©putation de lâ€™Ã©tablissement comptent pour toi. Tu pourrais rechercher une universitÃ© exigeante, reconnue et motivante, oÃ¹ tu pourras relever des dÃ©fis intellectuels. Si tu tâ€™y retrouves moins, câ€™est peut-Ãªtre que tu vois ton dÃ©part surtout comme une expÃ©rience de vie. Dans ce cas, lâ€™ouverture culturelle, la dÃ©couverte personnelle ou les relations que tu vas crÃ©er compteront autant, voire plus, que le prestige acadÃ©mique.",
      environment:
        "Si tu accordes du poids Ã  ces Ã©lÃ©ments, câ€™est que le lieu oÃ¹ tu vas vivre joue un rÃ´le important dans ton bien-Ãªtre. Le climat, la proximitÃ© de la nature, la possibilitÃ© dâ€™avoir ton indÃ©pendance ou de trouver un Ã©quilibre entre solitude et vie sociale peuvent Ãªtre essentiels pour toi. Si ce nâ€™est pas une prioritÃ©, cela veut dire que tu es sans doute plus adaptable. Ton choix dâ€™universitÃ© pourra alors se faire davantage en fonction des opportunitÃ©s acadÃ©miques ou sociales, sans que lâ€™environnement soit un critÃ¨re dÃ©cisif.",
      social:
        "Si tu tâ€™identifies Ã  ces questions, câ€™est que tu as envie de tâ€™intÃ©grer, de participer Ã  la vie collective et de rencontrer des personnes diffÃ©rentes, quâ€™elles soient crÃ©atives, ambitieuses ou venues dâ€™autres pays. Un campus vivant et multiculturel sera alors trÃ¨s stimulant pour toi. Si tu tâ€™y retrouves moins, câ€™est que tu privilÃ©gies probablement la qualitÃ© de tes relations Ã  leur quantitÃ©. Tu pourras alors tâ€™Ã©panouir dans un cadre plus calme, oÃ¹ les liens que tu tisseras seront peut-Ãªtre moins nombreux mais plus profonds."
    };

    const sys = [
      "RÃ©dige un rÃ©capitulatif narratif en franÃ§ais Ã  destination dâ€™un(e) lycÃ©en(ne) franÃ§ais(e).",
      "Garde un ton bienveillant, concret et nuancÃ© (jamais paternaliste).",
      "Produit 4 paragraphes (~120â€“180 mots chacun), sous forme de JSON STRICT avec les clÃ©s:",
      "self_learning, academic, environment, social.",
      "Nâ€™utilise pas les labels de clÃ© dans le texte; rends uniquement le JSON.",
      "Adapte le contenu aux signaux prÃ©sents dans la synthÃ¨se (objectifs, prioritÃ©s, format, langue, inquiÃ©tudes, etc.) et dans lâ€™historique."
    ].join("\n");

    const user = {
      summary,
      history_excerpt: compactHistory(history, 40),
      mapping_titles: {
        self_learning: "ğŸŒ± Connaissance de soi et apprentissage",
        academic: "ğŸ“ Ambitions acadÃ©miques",
        environment: "ğŸŒ Cadre de vie et environnement",
        social: "ğŸ¤ Relations sociales et ouverture"
      },
      style_constraints: {
        approx_word_count_each: "120-180",
        tone: "bienveillant, clair, nuancÃ©",
        audience: "lycÃ©en(ne) franÃ§ais(e)",
        avoid: ["rÃ©pÃ©titions", "jargon", "promesses excessives"]
      }
    };

    try {
      const out = await chat(
        [{ role: "system", content: sys }, { role: "user", content: J(user) }],
        { json: true, temperature: 0.5, max_tokens: 900 }
      );
      const parsed = safeParseJSON(out);
      if (!parsed || typeof parsed !== "object") return defaults;
      const keys = ["self_learning", "academic", "environment", "social"];
      for (const k of keys) if (typeof parsed[k] !== "string" || !parsed[k].trim()) parsed[k] = defaults[k];
      return parsed;
    } catch {
      return defaults;
    }
  };

  window.Agent = Agent;
})();
